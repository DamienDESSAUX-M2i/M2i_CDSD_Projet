<h1>Titre professionnel <em>Concepteur Développeur en Science des Données</em> (Jedha RNCP35288)</h1>

**Nomenclature du niveau de qualification :** Niveau 6

**Codes NSF :**
- 326 : Informatique, traitement de l'information, réseaux de transmission
- 114g : Mathématiques de l'informatique, mathématiques financières, statistique de la santé

**Formacodes :**
- 11052 : Mathématiques appliquées
- 11036 : Statistique
- 31028 : Intelligence artificielle
- 31026 : Data science

## Table des matières

- [Table des matières](#table-des-matières)
- [Blocs de competences du titre RNCP 35288](#blocs-de-competences-du-titre-rncp-35288)
  - [BC01 : Construction et alimentation d'une infrastructure de gestion de donnees](#bc01--construction-et-alimentation-dune-infrastructure-de-gestion-de-donnees)
  - [BC02 : Analyse exploratoire, descriptive et inferentielle de donnees](#bc02--analyse-exploratoire-descriptive-et-inferentielle-de-donnees)
  - [BC03 : Analyse predictive de donnees structurees par IA (Machine Learning)](#bc03--analyse-predictive-de-donnees-structurees-par-ia-machine-learning)
  - [BC04 : Analyse predictive de donnees non-structurees par IA (Deep Learning)](#bc04--analyse-predictive-de-donnees-non-structurees-par-ia-deep-learning)
  - [BC05 : Industrialisation d'un algorithme et automatisation des processus de decision](#bc05--industrialisation-dun-algorithme-et-automatisation-des-processus-de-decision)
  - [BC06 : Direction de projets de gestion de donnees](#bc06--direction-de-projets-de-gestion-de-donnees)
- [Modalités d'évaluation](#modalités-dévaluation)

## Blocs de competences du titre RNCP 35288

### BC01 : Construction et alimentation d'une infrastructure de gestion de donnees

- **C1.1** : Concevoir une architecture de   données robuste et adaptée en créant des lacs de données (Data Lake en   anglais) et des entrepôts de données (Data Warehouse en anglais) afin   de répondre aux besoins de stockage, d'utilisation, de sécurité et de   protection de l'organisation définie par un cahier des charges.

- **C1.2** : Intégrer la dimension de stockage et de calcul distribuée à   l'infrastructure de données via l'utilisation d'outils comme Spark ou AWS   Redshift afin de l'adapter à des besoins de gestion de données massives (Big   Data en anglais).

- **C1.3** : Collecter des données   provenant de différentes sources (Web, Logiciels internes de type Sage   / Excel ou externes de type Google Analytics) via des   librairies de programmation de type Scrapy ou Beautifulsoup   dans le respect des normes de protection des données utilisateurs définies dans le RGPD pour alimenter le Data Lake afin d'affiner le résultat d'analyses futures. 

- **C1.4** : Nettoyer et organiser les   données dans l'entrepôt de données (Data Warehouse en anglais) en   écrivant des processus d'extraction, transformation et chargements (ETL en   anglais) afin de rendre ces données disponibles et compréhensibles pour les   autres équipes métiers.

### BC02 : Analyse exploratoire, descriptive et inferentielle de donnees

- **C2.1** : Traiter des bases de données grâce à des analyses statistiques descriptives et inférentielles via des librairies de programmation comme Numpy ou Pandas, pour les organiser et les nettoyer afin de les normaliser par rapport à la population étudiée.

- **C2.2** : Effectuer des analyses univariées et multivariées sur des bases de données structurées afin de préciser des relations entre plusieurs variables et d'établir des liens statistiques entre elles.

- **C2.3** : Optimiser les analyses statistiques grâce au traitement parallélisé via l'utilisation d'outils comme Spark pour accélérer le temps de calcul d'un ordinateur afin de pouvoir analyser des volumes de données massifs (Big Data).

- **C2.4** : Présenter le résultat d'une analyse statistique de données structurées, massives ou non, grâce à des librairies de programmation comme Plotly ou Matplotlib pour synthétiser ce résultat devant un public profane afin de faciliter la prise de décisions et appuyer leurs déclinaisons opérationnelles.

### BC03 : Analyse predictive de donnees structurees par IA (Machine Learning)

- **C3.1** : Traiter des données   structurées en créant un pipeline de traitement grâce à des librairies de   programmation comme Scikit-Learn pour encoder, normaliser et découper   des données afin de les rendre interprétables par un algorithme   d'apprentissage automatique (Machine Learning en anglais).

- **C3.2** : Effectuer des analyses prédictives sur un jeu de données structurées   grâce à des algorithmes d'apprentissage automatique supervisés adaptés afin   d'automatiser des tâches liées aux résultats des prédictions de ces algorithmes.

- **C3.3** : Élaborer un algorithme d'apprentissage automatique non-supervisé pour segmenter une base de données en différents groupes homogènes ou réduire la dimension de cette dernière afin de pouvoir comprendre des observations de manière granulaire et de permettre leur visualisation.

- **C3.4** : Évaluer la performance prédictive des algorithmes d'apprentissage automatique en déterminant l'influence des différentes variables pour pouvoir l'améliorer afin de démontrer son utilité aux directions métiers, par rapport aux processus déjà établis dans l'organisation.

### BC04 : Analyse predictive de donnees non-structurees par IA (Deep Learning)

- **C4.1** : Traiter des données non-structurées (image, texte, audio) par la création de fonction de traitements via l'utilisation de librairies de programmation comme TensorFlow ou Numpy pour les transformer en matrices afin de les rendre interprétables par un algorithme d'apprentissage automatique profond (Deep learning en anglais).

- **C4.2** : Élaborer des réseaux de neurones adaptés (classiques, convolutifs ou recursifs) en superposant des couches neuronales via des librairies de programmation comme TensorFlow pour analyser des données non-structurées afin de détecter des signaux sur ces dernières.

- **C4.3** : Créer un algorithme robuste et précis en configurant un réseau de neurones pré-entrainé profond afin de répondre à des problématiques de prédiction sur des volumes de données massifs.

- **C4.4** : Créer des données non-structurées en élaborant des réseaux de neurones adverses afin de construire de nouvelles bases d'entrainement pour des applications d'intelligence artificielle.

- **C4.5** : Évaluer la performance d'un algorithme d'apprentissage automatique profond en évaluant des indicateurs sur des données d'entrainement et de validation afin d'industrialiser son utilisation.

### BC05 : Industrialisation d'un algorithme et automatisation des processus de decision

- **C5.1** : Standardiser la construction et l'environnement informatique d'un algorithme d'apprentissage automatique grâce des outils de production comme MLflow et Docker afin de faciliter la mise en production de projets d'intelligence artificielle sur tous types de plateformes.

- **C5.2** : Créer une interface de programmation applicative grâce à des outil comme AWS sagemaker afin de donner un accès à échelle aux prédictions des algorithmes d'apprentissage automatique à l'ensemble des équipes métiers concernées.

- **C5.3** : Déployer une application web intégrant des algorithmes de statistiques prédictives (Machine Learning et Deep Learning) grâce à des outils comme Flask, Heroku ou AWS sagemaker pour les rendre utilisables par l'ensemble des équipes métiers afin d'automatiser leurs processus de décision.

### BC06 : Direction de projets de gestion de donnees

- **C6.1** : Traduire les enjeux métiers en problématiques mathématiques/data grâce à une compréhension des besoins propres à chaque projet data afin de pouvoir répondre aux objectifs de l'organisation.

- **C6.2** : Maîtriser les technologies les plus récentes et adaptées du marché grâce à de la veille technologique et de la pratique constante pour développer une expertise afin d'être à même de proposer aux directions métiers les solutions les plus adaptées actuellement à une problématique et l'amélioration constante des process de gestion de données déjà en place.

- **C6.3** : Définir un cahier des charges, un retroplanning et un budget afin de défendre et détailler aux directions métier un projet data répondant aux besoins de l'organisation.

- **C6.4** : Gérer un projet d'analyse et de gestion de données (analyse statistique descriptive, Machine Learning, Deep Learning, Big Data ou non) grâce à l'élaboration d'indicateurs adaptés et de tableaux de bords, afin de faire le suivi et le bilan de l’action, ainsi que de la déclinaison opérationnelle de ses résultats, le tout dans le respect des normes de protection des données utilisateurs définies dans le RGPD.

- **C6.5** : Transmettre aux directions-métiers le process d'extraction d'informations et d'analyse de données en le vulgarisant afin de soutenir la mise en place d'une stratégie et d'actions futures.

- **C6.6** : Diriger un projet de gestion de données, allant de sa conception à la mise en place de solutions, afin de le mener jusqu'à son terme, d'être la personne clé disposant de toutes les informations sur le projet à tout moment, et d'accompagner d'autres services de l'organisation dans l'ensemble des activités relatives à celui-ci.

## Modalités d'évaluation

Bloc | Type d'évaluation | Thème d'évaluation
:- | :- | :-
BC01 | Une étude de cas sur des données réelles | Construction d'une infrastructure cloud accueillant des données Big Data (collecte de données web, intégration des données dans un Data Lake, nettoyage et chargement des données dans une base de données type AWS Redshift par traitement parallélisé si nécessaire via la construction d'un processus ETL).
BC02 | Deux études de cas sur des données réelles | Gestion de valeurs manquantes et aberrantes d'une base de données non-massives puis analyse pour déterminer et présenter des tendances par le biais de graphiques. Analyse d'une base de données massives déstructurées (Utilisation de Spark) adaptée à une problématique définie.
BC03 | Trois études de cas pratiques tirées de cas réels | Optimisation des processus marketing de qualification de prospect par le biais d'algorithmes d'apprentissage supervisés. Optimisation d'algorithmes d'apprentissage automatique supervisé sur des bases de données déséquilibrées. Localisation de zones de densité géographique par l'élaboration d'algorithmes d'apprentissage automatique non-supervisé.
BC04 | Une étude de cas pratique sur des données non-structurées | Analyse de sentiment, par l'élaboration d'un algorithme permettant de déterminer le sentiment d'un utilisateur à l'égard d'un produit (avec possibilité de créer de la nouvelle donnée pour agrémenter la base).
BC05 | Une étude de cas pratique sur le déploiement d'un algorithme d'apprentissage automatique | Web dashboard construction et mise en production d'une application web d'intelligence artificielle.
BC06 | Un projet data conçu de A à Z | Libre. Les apprenants peuvent préparer le projet data de leur choix. Celui-ci peut être personnel, développé par le candidat dans le cadre de son activité professionnelle, ou défini par une entreprise partenaire. Il fera l'objet d'une soutenance orale de 10 minutes suivie de 5 à 10 minutes de questions.
